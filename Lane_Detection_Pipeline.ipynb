{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global variables to save the left and the right lines from a previous frame\n",
    "import numpy as np\n",
    "global lastR, lastL\n",
    "global state\n",
    "\n",
    "lastR=np.array((0,0,0,0))\n",
    "lastL=np.array((0,0,0,0))\n",
    "state=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function is used to find the intersection points between the two lines(left & right) and the upper horizontal line(upper side of the mask) and the lower horizontal line(image hight)\n",
    "def getIntersectionWithHorizontal(firstLine,y):\n",
    "    import numpy as np\n",
    "    if firstLine[2]==firstLine[0]:\n",
    "        return np.nan\n",
    "    m=(firstLine[3]-firstLine[1])/(firstLine[2]-firstLine[0])\n",
    "    if m!=np.nan :\n",
    "        c=firstLine[3]-m*firstLine[2]\n",
    "        x=(y-c)/m\n",
    "        return np.int(x)\n",
    "    else:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7e59ffe098a1>:94: SyntaxWarning: name 'state' is used prior to global declaration\n",
      "  global state\n",
      "<ipython-input-3-7e59ffe098a1>:97: SyntaxWarning: name 'lastR' is assigned to before global declaration\n",
      "  global lastR, lastL\n",
      "<ipython-input-3-7e59ffe098a1>:97: SyntaxWarning: name 'lastL' is assigned to before global declaration\n",
      "  global lastR, lastL\n"
     ]
    }
   ],
   "source": [
    "#Pipeline algorithm\n",
    "def process_image(images):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    \n",
    "    # The libraries that we will need\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    %matplotlib inline\n",
    "    import math \n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    # converting the image to gray scale\n",
    "    imgGray=cv2.cvtColor(images,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Gaussian bluring (smoothing) with kernel 7\n",
    "    kernel=7\n",
    "    imgGray=cv2.GaussianBlur(imgGray,(kernel,kernel),0)\n",
    "\n",
    "    # Edge Detection using Canny algorithm\n",
    "    low_thr=100\n",
    "    high_thr=200\n",
    "    edges=cv2.Canny(imgGray,low_thr,high_thr)\n",
    "    #plt.imshow(edges,cmap='gray')\n",
    "\n",
    "    # mask to determine Rigion of Interest\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "    \n",
    "    imshape = images.shape\n",
    "    vertices = np.array([[(20,imshape[0]),(450, 310), (480,310), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "    #plt.imshow(masked_edges,'gray')\n",
    "\n",
    "    # Hough transform to find lines in the gray image\n",
    "    import math\n",
    "    rho=1\n",
    "    theta=np.pi/180\n",
    "    thr=5\n",
    "    min_line_length=10\n",
    "    max_line_gap=5\n",
    "    lines=cv2.HoughLinesP(masked_edges,rho,theta,thr,np.array([]),min_line_length,max_line_gap)\n",
    "    \n",
    "    # The next piece of code is used to get a right and a lift solid line by executing the following steps\n",
    "    # 1- Dividing the lines from Hough transform to two groups, right and left depending on their slopes\n",
    "    # 2- Determinig the largest line in each group and taking it as a reference\n",
    "    # 3- Getting the intersection points between the largest line and the upper (mask upper side) and lower (image height) horizental lines \n",
    "    # 4- Getting a line between these two intersection points\n",
    "    # 5- Getting the averge between the new lines and the previous ones in the previous frame\n",
    "    \n",
    "    line_image=np.copy(images)*0 #Image to save our lines (3 channel image)\n",
    "\n",
    "    #Variables to be used\n",
    "    largestRight=(0,0,0,0)\n",
    "    largestLeft=(0,0,0,0)\n",
    "    largestRightSize=0\n",
    "    largestLeftSize=0\n",
    "    \n",
    "    #step 1 (Dividing into two groups) and step 2 (Determining the largest line)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope=(y2-y1)/(x2-x1)\n",
    "            size=math.hypot(x2-x1,y2-y1)\n",
    "            if slope< -0.5:\n",
    "                if size>largestLeftSize:\n",
    "                    largestLeft=(x1,y1,x2,y2)\n",
    "            elif slope>0.5:\n",
    "                if size>largestRightSize:\n",
    "                    largestRight=(x1,y1,x2,y2)\n",
    "\n",
    "\n",
    "    # step 3 (Intersection points) and step 4 (getting the the two lines)\n",
    "    y1=320;# upper horizontal line (y of the mask upper side, it is a little bigger value for some tuning)\n",
    "    xl1=getIntersectionWithHorizontal(largestLeft,y1)+5 #Upper left point, integer 5 just for some tuning\n",
    "    xr1=getIntersectionWithHorizontal(largestRight,y1)#Upper right point\n",
    "\n",
    "    y2=imgGray.shape[0]; # Lower horizontal line (the height of the image)\n",
    "    xl2=getIntersectionWithHorizontal(largestLeft,y2) #Lower left point\n",
    "    xr2=getIntersectionWithHorizontal(largestRight,y2)#Lower right point\n",
    "\n",
    "    # step 5 (Getting the averge between the new lines and the previous ones in the previous frame)\n",
    "    # The value of lastR and lastL is updated every frame to be used in the next one that is why there are globally declared\n",
    "    #if xl1!=np.nan and xr1!=np.nan and xl2!=np.nan and xr2!=np.nan :\n",
    "    \n",
    "    if state:\n",
    "        lastR=[xr1,y1,xr2,y2]\n",
    "        lastL=[xl1,y1,xl2,y2]\n",
    "        global state\n",
    "        state=False\n",
    "    elif (not np.isnan(xl1)) and (not np.isnan(xr1)) and (not np.isnan(xl2)) and (not np.isnan(xr2)):\n",
    "        global lastR, lastL\n",
    "        lastR[0]=np.int((lastR[0]+xr1)/2)\n",
    "        lastR[2]=np.int((lastR[2]+xr2)/2)\n",
    "        lastR[1]=y1\n",
    "        lastR[3]=y2\n",
    "        lastL[0]=np.int((lastL[0]+xl1)/2)\n",
    "        lastL[2]=np.int((lastL[2]+xl2)/2)\n",
    "        lastL[1]=y1\n",
    "        lastL[3]=y2\n",
    "    \n",
    "    #Drawing the lines in an image  \n",
    "    cv2.line(line_image,(lastR[0],lastR[1]),(lastR[2],lastR[3]),(255,0,0),8)\n",
    "    cv2.line(line_image,(lastL[0],lastL[1]),(lastL[2],lastL[3]),(255,0,0),8)\n",
    "    \n",
    "    #flipping the line image into the original image\n",
    "    result=cv2.addWeighted(images,0.8,line_image,1,0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MoviePy: building video file white.mp4\n",
      "----------------------------------------\n",
      "\n",
      "Writing video into white.mp4\n",
      "|----------| 0/213   0% [elapsed: 00:00 left: ?, ? iters/sec]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/moviepy/audio/io/readers.py:110: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.nchannels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing video in white.mp4 !\n",
      "Your video is ready !\n",
      "CPU times: user 31.6 s, sys: 312 ms, total: 31.9 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "# The (process_image) pipeline is used to detect lane from a video\n",
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip('./solidWhiteRight.mp4')\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
